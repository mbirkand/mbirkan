<!DOCTYPE HTML>
<!--
	Forty by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Machine Learning</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
				<!-- Note: The "styleN" class below should match that of the banner element. -->
					<header id="header" class="alt style2">
						<a href="index.html" class="logo"><strong>HOME</strong> <span></span></a>
					<!--	<nav>
							<a href="#menu">Menu</a>
						</nav>
					-->
					</header>

				<!-- Menu -->
				<!--	<nav id="menu">
						<ul class="links">
							<li><a href="index.html">Home</a></li>
							<li><a href="landing.html">Landing</a></li>
							<li><a href="about.html">About</a></li>
							<li><a href="elements.html">Elements</a></li>
						</ul>
						<ul class="actions stacked">
							<li><a href="#" class="button primary fit">Get Started</a></li>
							<li><a href="#" class="button fit">Log In</a></li>
						</ul>
					</nav>
				-->
				
				<!-- Banner -->
				<!-- Note: The "styleN" class below should match that of the header element. -->
					<section id="banner" class="style2">
						<div class="inner">
							<span class="image">
								<img src="images/pic07.jpg" alt="" />
							</span>
							<header class="major">
								<h1>Machine Learning</h1>
							</header>
							<div class="content">
								<p>April 2024</p>
							</div>
						</div>
					</section>

				<!-- Main -->
					<div id="main">

						<!-- One -->
						<section id="one">
								<div class="inner">
									<header class="major">
									<h2>End of Module Assignment</h2>	
									</header>
							
		<!-- Buradan başladık -->						
			    <style>
        pre {
            background-color: #f4f4f4;
            border: 1px solid #ddd;
            border-radius: 4px;
            padding: 10px;
            overflow: auto;
        }
        code {
            font-family: 'Courier New', Courier, monospace;
        }
    </style>

		    <pre><code>
import numpy as np

def gradient_descent(x, y, iterations, learning_rate):
    m_curr = b_curr = 0
    n = len(x)
    cost_history = []

    for i in range(iterations):
        y_predicted = m_curr * x + b_curr
        cost = (1/n) * sum([val**2 for val in (y - y_predicted)])
        cost_history.append(cost)
        md = -(2/n) * sum(x * (y - y_predicted))
        bd = -(2/n) * sum(y - y_predicted)
        m_curr = m_curr - learning_rate * md
        b_curr = b_curr - learning_rate * bd
        print("m {}, b {}, cost {} iteration {}".format(m_curr, b_curr, cost, i))

    return cost_history

# Example usage:
x = np.array([1, 2, 3, 4, 5])
y = np.array([5, 7, 9, 11, 13])

# Initialize learning rates and iteration numbers
learning_rates = [0.001, 0.01, 0.05, 0.1]
iterations_list = [50, 100, 200]

best_learning_rate = None
best_iterations = None
min_cost = float('inf')

for learning_rate in learning_rates:
    for iterations in iterations_list:
        print(f"\nTesting with {iterations} iterations and learning rate {learning_rate}")
        cost_history = gradient_descent(x, y, iterations, learning_rate)
        final_cost = cost_history[-1]
        if final_cost < min_cost:
            min_cost = final_cost
            best_learning_rate = learning_rate
            best_iterations = iterations
        print(f"Final cost: {final_cost}")

print("\nBest parameters:")
print(f"Learning rate: {best_learning_rate}, Iterations: {best_iterations}, Minimum cost: {min_cost}")
    </code></pre>
							
								
		<!-- Buradan başladık -->							
<p style="text-align: justify;">This report shows the progression of my learning and application of machine learning principles throughout the module. It encompasses artefacts illustrating my comprehension of the challenges encountered during the Machine Learning module. The report further includes reflections on my individual contributions, collaborative efforts, and the overall impact on my professional and personal development.</p>
<p style="text-align: justify;color: #0e0e0e;"><br></p>
<p style="text-align: justify;"><strong>Unit 1</strong></p>
<p style="text-align: justify;">In Unit 1, we engaged with Schwab&rsquo;s (2016) article to understand the impact of Industry 4.0 on various sectors, as my I work In agriculture sector, I focused specifically on that. Industry 4.0 has significantly transformed agriculture by integrating advanced technologies that enhance efficiency, productivity, and sustainability. However, the dependency on sophisticated information systems introduces vulnerabilities. A notable example is the Amazon Web Services (AWS) outage in 2017, which disrupted farm management software, IoT devices, and supply chain logistics, highlighting the need for resilience and redundancy in these systems to mitigate the impact of potential failures and ensure the continuous operation of critical agricultural processes (Greene, 2017).</p>
<p style="text-align: justify;"><strong>Unit 3</strong></p>
<p style="text-align: justify;">In Unit 3, we conducted a series of practical exercises using Jupyter notebooks to observe the impact of changing data points on correlation and regression. The notebooks included:</p>
<p style="text-align: justify;">&bull; covariance_pearson_correlation.ipynb</p>
<p style="text-align: justify;">&bull; linear_regression.ipynb</p>
<p style="text-align: justify;">&bull; multiple_linear_regression.ipynb</p>
<p style="text-align: justify;">&bull; polynomial_regression.ipynb</p>
<ul style="list-style-type: disc;">
</ul>
<p style="text-align: justify;">These exercises enabled us to understand how variations in data influence statistical measures and regression models, reinforcing the importance of accurate data preprocessing in machine learning.</p>
<p style="text-align: justify;"><br></p>
<p style="text-align: justify;"><strong>Unit 4</strong></p>
<p style="text-align: justify;">In the Unit 2 activity, we conducted a correlation and regression analysis using the fuelconsumption.ipynb Jupyter Notebook with data from FuelConsumption.csv, deepening our understanding of these concepts in practical applications. We then extended this exercise using data from Global_Population.csv and Global_GDP.csv. First, we preprocessed the data by calculating the mean population and mean per capita GDP of each country from 2001 to 2021, addressing any missing values. We investigated the correlation between these variables, generating a scatter plot and evaluating the Pearson Correlation Coefficient, which helped interpret the strength and direction of the relationship. For regression analysis, we performed linear regression using the mean population as the independent variable and the mean per capita GDP as the dependent variable, generating a regression line and assessing the model&rsquo;s performance with metrics such as R&sup2;.&nbsp;</p>
<p style="text-align: justify;"><br></p>
<p style="text-align: justify;"><strong>Unit 5</strong>&nbsp;</p>
<p style="text-align: justify;">In Unit 5, we calculated the Jaccard coefficient to measure similarity between finite sample sets. The process involved converting asymmetric variables to binary values while retaining symmetric variables in their original form. This exercise provided insights into the practical application of similarity measures in machine learning, particularly in clustering and classification tasks. Answers based on the calculations are as follows:&nbsp;</p>
<p style="text-align: justify;">(Jack, Mary) = 0.33 - (Jack, Jim) = 0.6 - (Jim, Mary) = 0.75</p>
<p style="text-align: justify;"><br></p>
<p style="text-align: justify;"><strong>Unit 6</strong></p>
<p style="text-align: justify;">In Unit 6, we analyzed the Airbnb dataset as a group to determine factors influencing the likelihood of a listing being booked. The analysis involved data preprocessing followed by the application of K-Means clustering using the KMeans module from sklearn.cluster. We conducted tests to identify the optimal K-value, resulting in distinct group differences. Our findings indicated that price, number of reviews, location, and property type significantly influence booking likelihood. Notably, &lsquo;entire home/apartment&rsquo; was the most popular room type, and Manhattan was both the most listed and the most expensive neighborhood group. These insights can guide Airbnb&rsquo;s strategy to attract more hosts and guests, enhance platform engagement, and inform hosts and travelers about optimizing their listings and choices.</p>
<p style="text-align: justify;">In our group project, although we collaborated on all aspects together using Google Colab, I specifically focused on exploratory data analysis and preprocessing. I also created related figures and provided commentary on the conclusions.</p>
<p style="text-align: justify;">Report can be accessed <a href="/DPG1.pdf">here</a> </p>
<p style="text-align: justify;"><br></p>
<p style="text-align: justify;"><strong>Unit 7</strong></p>
<p style="text-align: justify;">In Unit 7, we explored the applicability and challenges of machine learning algorithms through practical exercises using the following files:</p>
<p style="text-align: justify;">&bull; simple_perceptron.ipynb</p>
<p style="text-align: justify;">&bull; perceptron_AND_operator.ipynb</p>
<p style="text-align: justify;">&bull; multi-layer_perceptron.ipynb</p>
<p style="text-align: justify;">These exercises facilitated a deeper understanding of perceptrons and multi-layer perceptrons, highlighting their potential and limitations in handling various datasets.</p>
<p style="text-align: justify;"><br></p>
<p style="text-align: justify;"><strong>Unit 8</strong></p>
<p style="text-align: justify;">In Unit 8, we critically appraised Hutson&rsquo;s article &ldquo;Robo-writers&rdquo; in Nature (2021) which discusses the growing use of AI for generating written content and its implications. Positively, AI can enhance administrative efficiency, automate routine tasks, and assist in content-heavy industries by producing news articles, marketing content, and scientific papers, thereby saving time and maintaining quality. Additionally, AI can improve accessibility and personalization, benefiting education and customer service.</p>
<p style="text-align: justify;">However, AI-generated content presents risks such as questionable quality, potential errors, and biases due to lack of human nuance. Ethical concerns include plagiarism, erosion of human authorship, and misinformation spread. Ensuring transparency and accountability in AI-generated content is challenging. The automation of writing tasks could impact employment in journalism, content creation, and administration, requiring workforce adaptation and retraining. Addressing these issues requires managing technical risks, handling biases, and establishing ethical guidelines to ensure the quality and reliability of AI-generated content.</p>
<p style="text-align: justify;">Additionally, we engaged in practical exercises to understand the impact of different parameters on the gradient descent cost function. By altering the iteration number and learning rate, we observed how the cost decreases during the optimization process. Initially, the gradient descent algorithm effectively reduced the cost function from 89.0 to approximately 0.0041 after 100 iterations, demonstrating convergence towards the minimum cost. Further experimentation involved testing different combinations of learning rates and iteration numbers to identify the optimal parameters. The final results indicated that a learning rate of 0.05 and 200 iterations yielded a minimum cost of 0.00106 The code for this optimization can be seen in the appendices section.</p>
<p style="text-align: justify;"><br></p>
<p style="text-align: justify;"><strong>Unit 9</strong></p>
<p style="text-align: justify;">In Unit 9, we examined the ethical and social implications of Convolutional Neural Networks (CNNs) through Wall&rsquo;s (2019) article. The article highlights significant concerns such as bias and fairness, where models trained on biased datasets can perpetuate discrimination, particularly in facial recognition and surveillance. Privacy issues arise from CNNs&rsquo; ability to recognize individuals, potentially leading to mass surveillance and privacy erosion. Job displacement is another concern, with automation affecting sectors like radiology and manufacturing. CNNs are also vulnerable to adversarial attacks, posing security risks. Ethical data use is crucial, given the vast amounts of labeled data required for training, emphasizing the need for ethically sourced data. Machine learning professionals face a range of legal, social, ethical, and professional issues. Legal challenges include complying with data protection laws like GDPR, managing intellectual property, and addressing liability for model failures. Social issues involve the impacts of automation, ensuring fairness in predictions, and preventing misuse of technology. Ethical concerns encompass maintaining transparency, addressing biases, and ensuring data privacy. Additionally, professionals must prioritize continuous development, uphold ethical standards, and foster collaborative work environments (Wall, 2019).</p>
<p style="text-align: justify;">Following this theoretical exploration, I implemented a CNN model for object recognition using the CIFAR-10 dataset. By altering the index value in the code, I observed varying prediction outcomes. While the model correctly identified a ship, cat, and frog at certain indexes, it misidentified an airplane as a deer and a ship as an airplane at others. These observations underscore the importance of extensive testing and iterative refinement to accurately evaluate and improve model performance. This unit highlighted the necessity for balancing technical capabilities with ethical responsibilities in deploying advanced machine learning models.</p>
<p style="text-align: justify;">Changing the index from 16 to 10 resulted in the model predicting a deer, whereas the actual image was an airplane. Further changes to the index value (2, 5, 8) produced correct predictions (a ship, a cat, a frog). However, when the index was set to 15, the model incorrectly predicted an airplane while the actual image was a ship. Code of the project can be seen in the appendices. These observations underscore the importance of extensive testing and iteration to accurately evaluate the model&rsquo;s error rate.</p>
<p style="text-align: justify;"><br></p>
<p style="text-align: justify;"><strong>Unit 11</strong></p>
<p style="text-align: justify;">In Unit 11, we ran the model_Performance_Measurement.ipynb file and modified parameters to observe their impact on metrics such as AUC and R&sup2; error. Initially, the model&rsquo;s performance on a classification dataset showed an accuracy of 0.88, with a precision of 0.8831, a recall of 0.8782, and F1 scores (macro, micro, and weighted) of approximately 0.88. The ROC AUC score was 0.9103, indicating good discrimination between classes. Detailed results indicated high precision and recall for both classes, with a balanced performance across the metrics.</p>
<p style="text-align: justify;">Subsequently, we applied a logistic regression model to the breast cancer dataset, achieving a higher accuracy of 0.958. The precision was 0.9503, recall was 0.9628, and the F1 scores were similarly high, reflecting a strong balance between precision and recall. The ROC AUC score of 0.9948 further confirmed the model&rsquo;s excellent performance in distinguishing between classes. Code can be seen in the appendices section.</p>
<p style="text-align: justify;">The VC model on the classification dataset provided the following insights:</p>
<p style="text-align: justify;">&bull; Accuracy (0.88)</p>
<p style="text-align: justify;">&bull; Precision (0.8831): Reflecting a high ratio of true positive predictions to total predicted positives.</p>
<p style="text-align: justify;">&bull; Recall (0.8782): Indicating a high ratio of true positive predictions to total actual positives.</p>
<p style="text-align: justify;">&bull; F1 Score: Combining precision and recall, with macro and weighted averages considering class balance.</p>
<p style="text-align: justify;">&bull; ROC AUC Score (0.9103): Demonstrating strong capability in class differentiation.</p>
<p style="text-align: justify;"><br></p>
<img src="ML1.png" alt="1" width="500" height=“333">
<img src="ML2.png" alt="1" width="500" height=“333">
									
<p style="text-align: justify;"><strong>Figure 1.</strong> Predicted vs True label</p>
<p style="text-align: justify;">For the logistic regression model on the breast cancer dataset, the results were:</p>
<ul style="list-style-type: disc;">
    <li style="text-align: justify;">Higher Accuracy (0.958):</li>
</ul>
<p style="text-align: justify;">&bull; High Precision and Recall: Both metrics were high, indicating effective identification of true positives with minimal false positives and negatives.</p>
<p style="text-align: justify;">&bull; High F1 Scores: Reflecting a good balance between precision and recall.</p>
<p style="text-align: justify;">&bull; ROC AUC Score (0.9948): Indicating excellent performance.</p>
<p style="text-align: justify;">Additionally, regression metrics included:</p>
<p style="text-align: justify;">&bull; RMSE (0.6124): Measuring average error magnitude, with lower values indicating better fit.</p>
<p style="text-align: justify;">&bull; MAE (0.5): Measuring average absolute error, with lower values indicating better performance.</p>
<p style="color: #0e0e0e;"><br></p>

<img src="ML3.png" alt="1" width="500" height=“333">
<img src="ML4.png" alt="1" width="500" height=“333">
<img src="ML5.png" alt="1" width="500" height=“333">

									
<p style="text-align: justify;">Figure 2. False vs true positive rate</p>
<p style="text-align: justify;"><br></p>
<p style="text-align: justify;"><strong>Unit 12</strong></p>
<p style="text-align: justify;">In the final project on image classification using the CIFAR-10 dataset, we split the original training set into a training set and a validation set using an 80-20 ratio, resulting in 40,000 training images and 10,000 validation images. The CIFAR-10 dataset contains 60,000 32x32 color images across 10 classes, each class having 6,000 images. This partitioning was crucial for fine-tuning the model and monitoring its performance on unseen data, helping to prevent overfitting and providing a more accurate measure of the model&rsquo;s performance.</p>
<p style="text-align: justify;">Our neural network architecture included multiple convolutional layers to capture spatial hierarchies, MaxPooling layers to reduce dimensionality, and Dropout layers to prevent overfitting. We used the ReLU activation function for its efficiency and the softmax activation function in the output layer for multi-class classification. The categorical cross-entropy loss function measured the difference between the true and predicted labels. Over 50 epochs, both training and validation loss steadily declined, indicating effective learning. We employed data augmentation to enhance generalization and the Adam optimizer for efficient training. Despite achieving a test accuracy of 68.29% and a test loss of 0.9502, the model struggled with certain classes like birds and cats, which had lower precision and recall. Future work includes exploring more complex architectures, additional regularization techniques, and transfer learning to improve overall performance. This project highlighted the importance of model validation and potential areas for further optimization. Additionally, the e-portfolio assignment on CNN in Unit 9 greatly aided in understanding the dataset and refining our approach.</p>
<p style="text-align: justify;"><br></p>
<p style="text-align: justify;"><strong>Conclusion</strong></p>
<p style="text-align: justify;">This report highlights my learning journey and development throughout the module, emphasizing my understanding and application of machine learning principles. Through practical exercises and critical appraisals, I have explored the ethical, social, and technical challenges in machine learning, from data preprocessing to neural network training. The artefacts from each unit demonstrate my growth in handling complex concepts and practical implementations, such as the CNN model for image classification using the CIFAR-10 dataset. These experiences underscored the importance of model validation, parameter tuning, and iterative refinement. Collaborative activities and individual contributions have enhanced my ability to work effectively in teams, manage projects, and communicate findings.</p>
<p style="color: #0e0e0e;"><br></p>
<p style="text-align: justify;"><strong>References</strong></p>
<p style="text-align: justify;">Schwab, K. (2016). The Fourth Industrial Revolution: what it means, how to respond. <em>World Economic Forum</em>. Retrieved from <a href="https://www.weforum.org/agenda/2016/01/the-fourth-industrial-revolution-what-it-means-and-how-to-respond/"><u>https://www.weforum.org/agenda/2016/01/the-fourth-industrial-revolution-what-it-means-and-how-to-respond/</u></a></p>
<p style="text-align: justify;">Greene, J. (2017). Amazon explains the AWS outage. <em>CNBC</em>. Retrieved from <a href="https://www.cnbc.com/2017/03/02/amazon-explains-the-aws-outage.html"><u>https://www.cnbc.com/2017/03/02/amazon-explains-the-aws-outage.html</u></a></p>
<p style="text-align: justify;">Hutson, M., 2021. Robo-writers: the rise and risks of language-generating AI. <em>Nature</em>, 591(7851), pp.22-25. Available at: https://doi.org/10.1038/d41586-021-00530-0 [Accessed 27 June 2024]</p>
<p style="text-align: justify;">Wall, M., 2019. Ethical and Social Implications of CNN Technology. <em>Journal of Technology and Ethics</em>, [online]</p>
<p style="color: #0e0e0e;"><br></p>
<p style="text-align: justify;"><br></p>

<p style="text-align: justify;"><strong>Appendices</strong></p>
<p style="text-align: justify;"><strong>Unit 8 Code</strong></p>
<p>import numpy as np&nbsp;</p>
<p><br></p>
<p>def gradient_descent(x, y, iterations, learning_rate):</p>
<p>&nbsp; &nbsp;&nbsp;m_curr = b_curr = 0</p>
<p>&nbsp; &nbsp;&nbsp;n = len(x)</p>
<p>&nbsp; &nbsp;&nbsp;cost_history = []</p>
<p><br></p>
<p>&nbsp; &nbsp;&nbsp;for i in range(iterations):</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;y_predicted = m_curr * x + b_curr</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;cost = (1/n) * sum([val**2 for val in (y - y_predicted)])</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;cost_history.append(cost)</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;md = -(2/n) * sum(x * (y - y_predicted))</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;bd = -(2/n) * sum(y - y_predicted)</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;m_curr = m_curr - learning_rate * md</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;b_curr = b_curr - learning_rate * bd</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;print(&quot;m {}, b {}, cost {} iteration {}&quot;.format(m_curr, b_curr, cost, i))</p>
<p><br></p>
<p>&nbsp; &nbsp;&nbsp;return cost_history</p>
<p><br></p>
<p># Example usage:</p>
<p>x = np.array([1, 2, 3, 4, 5])</p>
<p>y = np.array([5, 7, 9, 11, 13])</p>
<p><br></p>
<p># Initialize learning rates and iteration numbers</p>
<p>learning_rates = [0.001, 0.01, 0.05, 0.1]</p>
<p>iterations_list = [50, 100, 200]</p>
<p><br></p>
<p>best_learning_rate = None</p>
<p>best_iterations = None</p>
<p>min_cost = float(&apos;inf&apos;)</p>
<p><br></p>
<p>for learning_rate in learning_rates:</p>
<p>&nbsp; &nbsp;&nbsp;for iterations in iterations_list:</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;print(f&quot;\nTesting with {iterations} iterations and learning rate {learning_rate}&quot;)</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;cost_history = gradient_descent(x, y, iterations, learning_rate)</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;final_cost = cost_history[-1]</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;if final_cost &lt; min_cost:</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;min_cost = final_cost</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;best_learning_rate = learning_rate</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;best_iterations = iterations</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;print(f&quot;Final cost: {final_cost}&quot;)</p>
<p><br></p>
<p>print(&quot;\nBest parameters:&quot;)</p>
<p>print(f&quot;Learning rate: {best_learning_rate}, Iterations: {best_iterations}, Minimum cost: {min_cost}&rdquo;)</p>
<p><br></p>
<p><br></p>
<p><br></p>
<p><strong>Unit 9</strong></p>
<p><br></p>
<p>import numpy as np</p>
<p>import matplotlib.pyplot as plt</p>
<p>from keras.datasets import cifar10</p>
<p>from keras.models import Sequential</p>
<p>from keras.layers import Dense, Conv2D, MaxPool2D, Flatten</p>
<p>from keras.utils import to_categorical</p>
<p>from sklearn.metrics import classification_report, confusion_matrix</p>
<p style="background-color: #ffffff;"><br></p>
<p># Load the dataset</p>
<p>(x_train_all, y_train_all), (x_test, y_test) = cifar10.load_data()</p>
<p>LABEL_NAMES = [&apos;airplane&apos;, &apos;automobile&apos;,&apos;bird&apos;,&apos;cat&apos;, &apos;deer&apos;, &apos;dog&apos;, &apos;frog&apos;, &apos;horse&apos;, &apos;ship&apos;, &apos;truck&apos;]</p>
<p style="background-color: #ffffff;"><br></p>
<p># Preprocess the data</p>
<p>x_train_all = x_train_all / 255.0</p>
<p>x_test = x_test / 255.0</p>
<p style="background-color: #ffffff;"><br></p>
<p>y_cat_train_all = to_categorical(y_train_all, 10)</p>
<p>y_cat_test = to_categorical(y_test, 10)</p>
<p style="background-color: #ffffff;"><br></p>
<p># Create the model</p>
<p>model = Sequential()</p>
<p>model.add(Conv2D(filters=32, kernel_size=(4,4),input_shape=(32, 32, 3), activation=&apos;relu&apos;,))</p>
<p>model.add(MaxPool2D(pool_size=(2, 2)))</p>
<p>model.add(Conv2D(filters=32, kernel_size=(4,4), activation=&apos;relu&apos;))</p>
<p>model.add(MaxPool2D(pool_size=(2, 2)))</p>
<p>model.add(Flatten())</p>
<p>model.add(Dense(256, activation=&apos;relu&apos;))</p>
<p>model.add(Dense(10, activation=&apos;softmax&apos;))</p>
<p style="background-color: #ffffff;"><br></p>
<p>model.compile(loss=&apos;categorical_crossentropy&apos;,</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;optimizer=&apos;adam&apos;,</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;metrics=[&apos;accuracy&apos;])</p>
<p style="background-color: #ffffff;"><br></p>
<p># Train the model</p>
<p>model.fit(x_train_all, y_cat_train_all, epochs=10, validation_data=(x_test, y_cat_test))</p>
<p style="background-color: #ffffff;"><br></p>
<p># Change the value of the variable to test different images (value between 1 and 15)</p>
<p>index = 2&nbsp;&nbsp;# Example value, change this to test different images</p>
<p style="background-color: #ffffff;"><br></p>
<p># Display the image</p>
<p>plt.imshow(x_test[index])</p>
<p>plt.show()</p>
<p style="background-color: #ffffff;"><br></p>
<p># Predict the class</p>
<p>my_image = x_test[index]</p>
<p>prediction = np.argmax(model.predict(my_image.reshape(1, 32, 32, 3)), axis=-1)</p>
<p>predicted_label = LABEL_NAMES[prediction[0]]</p>
<p>true_label = LABEL_NAMES[y_test[index][0]]</p>
<p style="background-color: #ffffff;"><br></p>
<p>print(f&quot;Predicted: {predicted_label}, Actual: {true_label}&quot;)</p>
<p style="background-color: #ffffff;"><br></p>
<p style="background-color: #ffffff;"><br></p>
<p style="background-color: #ffffff;"><br></p>
<p style="background-color: #ffffff;"><br></p>
<p style="background-color: #ffffff;"><strong>Unit 11</strong></p>
<p><br></p>
<p>import numpy as np</p>
<p>import matplotlib.pyplot as plt</p>
<p>from sklearn.datasets import make_classification, load_breast_cancer, load_iris</p>
<p>from sklearn.model_selection import train_test_split</p>
<p>from sklearn.svm import SVC</p>
<p>from sklearn.linear_model import LogisticRegression</p>
<p>from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score, accuracy_score, precision_score, recall_score, classification_report, roc_auc_score, roc_curve, auc, mean_squared_error, mean_absolute_error, r2_score, log_loss</p>
<p>from sklearn.preprocessing import label_binarize</p>
<p>from sklearn.multiclass import OneVsRestClassifier</p>
<p style="background-color: #ffffff;"><br></p>
<p># Define a function to display the performance metrics</p>
<p>def display_metrics(y_true, y_pred, y_prob=None):</p>
<p>&nbsp; &nbsp;&nbsp;print(&quot;Confusion Matrix:&quot;)</p>
<p>&nbsp; &nbsp;&nbsp;cm = confusion_matrix(y_true, y_pred)</p>
<p>&nbsp; &nbsp;&nbsp;disp = ConfusionMatrixDisplay(confusion_matrix=cm)</p>
<p>&nbsp; &nbsp;&nbsp;disp.plot()</p>
<p>&nbsp; &nbsp;&nbsp;plt.show()</p>
<p style="background-color: #ffffff;"><br></p>
<p>&nbsp; &nbsp;&nbsp;print(f&quot;Accuracy: {accuracy_score(y_true, y_pred)}&quot;)</p>
<p>&nbsp; &nbsp;&nbsp;print(f&quot;Precision: {precision_score(y_true, y_pred, average=&apos;macro&apos;)}&quot;)</p>
<p>&nbsp; &nbsp;&nbsp;print(f&quot;Recall: {recall_score(y_true, y_pred, average=&apos;macro&apos;)}&quot;)</p>
<p>&nbsp; &nbsp;&nbsp;print(f&quot;F1 Score (Macro): {f1_score(y_true, y_pred, average=&apos;macro&apos;)}&quot;)</p>
<p>&nbsp; &nbsp;&nbsp;print(f&quot;F1 Score (Micro): {f1_score(y_true, y_pred, average=&apos;micro&apos;)}&quot;)</p>
<p>&nbsp; &nbsp;&nbsp;print(f&quot;F1 Score (Weighted): {f1_score(y_true, y_pred, average=&apos;weighted&apos;)}&quot;)</p>
<p>&nbsp; &nbsp;&nbsp;print(classification_report(y_true, y_pred))</p>
<p style="background-color: #ffffff;"><br></p>
<p>&nbsp; &nbsp;&nbsp;if y_prob is not None:</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;print(f&quot;ROC AUC Score: {roc_auc_score(y_true, y_prob)}&quot;)</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;fpr, tpr, _ = roc_curve(y_true, y_prob)</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;plt.figure()</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;plt.plot(fpr, tpr, color=&quot;darkorange&quot;, lw=2, label=&quot;ROC curve (area = %0.2f)&quot; % roc_auc_score(y_true, y_prob))</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;plt.plot([0, 1], [0, 1], color=&quot;navy&quot;, lw=2, linestyle=&quot;--&quot;)</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;plt.xlim([0.0, 1.0])</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;plt.ylim([0.0, 1.05])</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;plt.xlabel(&quot;False Positive Rate&quot;)</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;plt.ylabel(&quot;True Positive Rate&quot;)</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;plt.title(&quot;Receiver operating characteristic example&quot;)</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;plt.legend(loc=&quot;lower right&quot;)</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;plt.show()</p>
<p style="background-color: #ffffff;"><br></p>
<p># Generate classification data and split into train/test sets</p>
<p>X, y = make_classification(random_state=0)</p>
<p>X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)</p>
<p style="background-color: #ffffff;"><br></p>
<p># Train and evaluate SVC model</p>
<p>clf = SVC(random_state=0, probability=True)</p>
<p>clf.fit(X_train, y_train)</p>
<p>predictions = clf.predict(X_test)</p>
<p>y_prob = clf.predict_proba(X_test)[:, 1]</p>
<p>display_metrics(y_test, predictions, y_prob)</p>
<p style="background-color: #ffffff;"><br></p>
<p># Load breast cancer dataset and evaluate Logistic Regression model</p>
<p>X, y = load_breast_cancer(return_X_y=True)</p>
<p>X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)</p>
<p>clf = LogisticRegression(solver=&quot;liblinear&quot;, random_state=0)</p>
<p>clf.fit(X_train, y_train)</p>
<p>predictions = clf.predict(X_test)</p>
<p>y_prob = clf.predict_proba(X_test)[:, 1]</p>
<p>display_metrics(y_test, predictions, y_prob)</p>
<p style="background-color: #ffffff;"><br></p>
<p># Load iris dataset and evaluate OneVsRest SVM model for multiclass classification</p>
<p>iris = load_iris()</p>
<p>X, y = iris.data, iris.target</p>
<p>y = label_binarize(y, classes=[0, 1, 2])</p>
<p>n_classes = y.shape[1]</p>
<p>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)</p>
<p>classifier = OneVsRestClassifier(SVC(kernel=&quot;linear&quot;, probability=True, random_state=0))</p>
<p>y_score = classifier.fit(X_train, y_train).decision_function(X_test)</p>
<p style="background-color: #ffffff;"><br></p>
<p># Compute ROC curve and ROC area for each class</p>
<p>fpr = dict()</p>
<p>tpr = dict()</p>
<p>roc_auc = dict()</p>
<p>for i in range(n_classes):</p>
<p>&nbsp; &nbsp;&nbsp;fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])</p>
<p>&nbsp; &nbsp;&nbsp;roc_auc[i] = auc(fpr[i], tpr[i])</p>
<p style="background-color: #ffffff;"><br></p>
<p># Compute micro-average ROC curve and ROC area</p>
<p>fpr[&quot;micro&quot;], tpr[&quot;micro&quot;], _ = roc_curve(y_test.ravel(), y_score.ravel())</p>
<p>roc_auc[&quot;micro&quot;] = auc(fpr[&quot;micro&quot;], tpr[&quot;micro&quot;])</p>
<p>plt.figure()</p>
<p>lw = 2</p>
<p>plt.plot(fpr[2], tpr[2], color=&quot;darkorange&quot;, lw=lw, label=&quot;ROC curve (area = %0.2f)&quot; % roc_auc[2])</p>
<p>plt.plot([0, 1], [0, 1], color=&quot;navy&quot;, lw=lw, linestyle=&quot;--&quot;)</p>
<p>plt.xlim([0.0, 1.0])</p>
<p>plt.ylim([0.0, 1.05])</p>
<p>plt.xlabel(&quot;False Positive Rate&quot;)</p>
<p>plt.ylabel(&quot;True Positive Rate&quot;)</p>
<p>plt.title(&quot;Receiver operating characteristic example&quot;)</p>
<p>plt.legend(loc=&quot;lower right&quot;)</p>
<p>plt.show()</p>
<p style="background-color: #ffffff;"><br></p>
<p># Regression metrics</p>
<p>y_true = [3, -0.5, 2, 7]</p>
<p>y_pred = [2.5, 0.0, 2, 8]</p>
<p>print(f&quot;RMSE: {mean_squared_error(y_true, y_pred, squared=False)}&quot;)</p>
<p>print(f&quot;MAE: {mean_absolute_error(y_true, y_pred)}&quot;)</p>
<p>print(f&quot;R2 Score: {r2_score(y_true, y_pred)}&quot;)</p>						
									
									
		</div>							
		</section>								
	<!-- Buradan başladık -->
								
								
								
								
								
								
								</div>
							</section>

					

				<!-- Footer -->
					<footer id="footer">
						<div class="inner">
							<ul class="icons">
								<li><a href="https://github.com/mbirkand" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
								<li><a href="https://www.linkedin.com/in/mbirkandurak" class="icon brands alt fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
							</ul>
					
						</div>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
